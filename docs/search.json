[
  {
    "objectID": "Data_vis.html",
    "href": "Data_vis.html",
    "title": "Data Visualisation Experience",
    "section": "",
    "text": "I would consider myself more of an engineer than designer and have been focused on bringing best engineering practices to the world of data visualisation.\nStandardisation Version control Abstraction"
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "Oliver Jones",
    "section": "",
    "text": "Quarto testing\nUsing guidance published here: https://quarto.org/docs/publishing/github-pages.html"
  },
  {
    "objectID": "Data_eng.html",
    "href": "Data_eng.html",
    "title": "Data Engineering Experience",
    "section": "",
    "text": "Data Engineering Experience"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Oli Jones",
    "section": "",
    "text": "I am a data engineer and BI developer working for the NHS. My current focus is bringing software engineering principles to data visualisation.\n\nEnd to End data & visualisation developer with experience in data sourcing & management, SQL & workflow build and data visualisation.\nExperience working within an Agile development team using a range of technologies including Azure, SAS, Hadoop and Google Cloud Platform.\nDetail orientated and logical approach to problem solving demonstrated during solution analysis/design and investigation of report reconciliation breaks.\n\n\n\nSee ‘My Work’ section for software i have used."
  },
  {
    "objectID": "index.html#more-about-me",
    "href": "index.html#more-about-me",
    "title": "Oli Jones",
    "section": "",
    "text": "See ‘My Work’ section for software i have used."
  },
  {
    "objectID": "About.html",
    "href": "About.html",
    "title": "Work Experience",
    "section": "",
    "text": "2021 - Present\nBusiness Intelligence developer focused on building visualisation products to be used to support decision making for healthcare professionals to improve patient experience.\nMy responsibilities include:\n\nEnd to end Tableau development (stakeholder engagement, requirements & design, data sourcing, dashboard build, UAT & handover to stakeholders)\nImprove Tableau development operating model - this includes setting up systems and processes for collecting requirements that can be used to improve developers efficiency.\nData pipeline build in python on Azure\nRun visualisation tool proof of concepts to expand the offering of the team (currently looking at using Streamlit and other web app tools to display data to users)\n\nTools used:\n\nTableau\nSQL\nPython\nAzure\n\n\n\n\n2016 - 2021\nData developer and analyst on a project focused on migrating legacy financial reporting systems onto Google Cloud.\nMy responsibilities include:\n\nSQL development with several different Google scrums involving converting SAS jobs to run on Google and uplifting current Google BigQuery SQLs/workflows. Experience with development of several concurrent code branches managed with JIRA & GitHub.\nCreation and integration of data workflows to allow two large reporting batches to run as one integrated batch.\nBatch monitoring and troubleshooting using Google logging tools.\nData management including data sourcing using SFTP & Hadoop to migrate data from On-premise systems to Google Cloud, building & maintaining table schemas and creating extracts\nCoordinating deployments from GitHub to UAT/Production environments using Jenkins\nData model and dashboard build using Tableau for a range of MI products\nStakeholder support during UAT/transition to investigate and resolve any bugs that arise\nApplication SME for the migration from On-premise SAS to Google Cloud – Guided Google specific design issues, coordinating code/environment integration and managing the technical side of UAT.\nReporting Framework PoC – This included building a tool in Appian to capture reporting framework requirements. I was responsible for the design of the back end data model and build in Appian\nEnd user tool testing – Configuration and user testing of workflow management tool, adjustment tool and validation frameworks.\nMentoring and training of junior team members\n\nTools used:\n\nTableau\nSQL\nSAS\nGoogle cloud\nShell scripting\nHadoop"
  },
  {
    "objectID": "About.html#current-nhs-england---bi-developer",
    "href": "About.html#current-nhs-england---bi-developer",
    "title": "Work Experience",
    "section": "",
    "text": "2021 - Present\nBusiness Intelligence developer focused on building visualisation products to be used to support decision making for healthcare professionals to improve patient experience.\nMy responsibilities include:\n\nEnd to end Tableau development (stakeholder engagement, requirements & design, data sourcing, dashboard build, UAT & handover to stakeholders)\nImprove Tableau development operating model - this includes setting up systems and processes for collecting requirements that can be used to improve developers efficiency.\nData pipeline build in python on Azure\nRun visualisation tool proof of concepts to expand the offering of the team (currently looking at using Streamlit and other web app tools to display data to users)\n\nTools used:\n\nTableau\nSQL\nPython\nAzure"
  },
  {
    "objectID": "About.html#previous-hsbc---senior-bi-developer",
    "href": "About.html#previous-hsbc---senior-bi-developer",
    "title": "Work Experience",
    "section": "",
    "text": "2016 - 2021\nData developer and analyst on a project focused on migrating legacy financial reporting systems onto Google Cloud.\nMy responsibilities include:\n\nSQL development with several different Google scrums involving converting SAS jobs to run on Google and uplifting current Google BigQuery SQLs/workflows. Experience with development of several concurrent code branches managed with JIRA & GitHub.\nCreation and integration of data workflows to allow two large reporting batches to run as one integrated batch.\nBatch monitoring and troubleshooting using Google logging tools.\nData management including data sourcing using SFTP & Hadoop to migrate data from On-premise systems to Google Cloud, building & maintaining table schemas and creating extracts\nCoordinating deployments from GitHub to UAT/Production environments using Jenkins\nData model and dashboard build using Tableau for a range of MI products\nStakeholder support during UAT/transition to investigate and resolve any bugs that arise\nApplication SME for the migration from On-premise SAS to Google Cloud – Guided Google specific design issues, coordinating code/environment integration and managing the technical side of UAT.\nReporting Framework PoC – This included building a tool in Appian to capture reporting framework requirements. I was responsible for the design of the back end data model and build in Appian\nEnd user tool testing – Configuration and user testing of workflow management tool, adjustment tool and validation frameworks.\nMentoring and training of junior team members\n\nTools used:\n\nTableau\nSQL\nSAS\nGoogle cloud\nShell scripting\nHadoop"
  }
]